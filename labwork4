import numpy as np 
import pandas as pd
from sklearn.model_selection import train_test_split, KFold , cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
data_path_1 = r'./labwork2/abalone.csv'
data_path_2 = r'./labwork2/Raisin_Dataset.xlsx'

def take_data_1(path):
    dataset = pd.read_csv(path,header = None)
    dataset.columns = ["Sex", "Length", "Diameter", "Height", "Whole weight",
                                 "Shucked weight", "Viscera weight", "Shell weight", "Rings"]
    Sex_mapping = {'M': 0, "F": 1, "I": 2}
    dataset["Sex"] = dataset["Sex"].map(Sex_mapping)
    columns_2 = list(dataset.columns.values.tolist())
    column_names_2 = [column_name for column_name in columns_2 if column_name != "Rings" and column_name != "Sex"]
    X_data = dataset.loc[:, column_names_2].values
    #Y_data = dataset.loc[:,["Rings"]]
    Y_data = dataset["Rings"].values
    x_train, x_test , y_train , y_test = train_test_split(X_data, Y_data, test_size=0.2, train_size= 0.8, random_state= 0)
    x_train_st , x_test_st = standarlization(x_train, x_test)
    return x_train_st , x_test_st, y_train , y_test

def take_data_2(path):
    dataset = pd.read_excel(path,header = 0)
    columns = list(dataset.columns.values.tolist())
    Class_mapping ={'Kecimen':0, 'Besni':1}
    dataset["Class"] = dataset["Class"].map(Class_mapping)
    column_names_1 = [column_name for column_name in columns if column_name != "Class"]
    X_data = dataset.loc[:,column_names_1].values
    Y_data = dataset.loc[:,["Class"]].values
    return X_data, Y_data

def random_forest(X_data, Y_data):
    kfold = KFold(n_splits= 101)
    errors = []
    for train_index, test_index in kfold.split(X_data):
       
        X_train , X_test = X_data[train_index ] , X_data[test_index]
        y_train , y_test = Y_data[train_index] , Y_data[test_index]
        pipeline = Pipeline(steps= [('scaler', StandardScaler()),('RandomForest', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1))], verbose= True)
        
        pipeline.fit(X_train, y_train.ravel())
        y_predict = pipeline.predict(X_test)
        error = 1 - pipeline.score(X_test,y_test.ravel())
        errors.append(error)

        """ print("TRAIN:", train_index, "TEST:", test_index)
    ...     X_train, X_test = X[train_index], X[test_index]
    ...     y_train, y_test = y[train_index], y[test_index]"""
    print(errors)


def standarlization(x_train , x_test):
    st = StandardScaler()
    x_train_standardlized = st.fit_transform(x_train)
    x_test_standardlized = st.fit_transform(x_test)
    return x_train_standardlized , x_test_standardlized

def decision_tree(x_train, x_test , y_train , y_test):
    classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  
    classifier.fit(x_train, y_train) 
    y_pred=classifier.predict(x_test) 
    accuracy = accuracy_score(y_test,y_pred)
    error = 1 - accuracy
    print(f'the error in this model is : {error}')

x_train , x_test , y_train , y_test = take_data_1(data_path_1)
print("part 1")
decision_tree(x_train , x_test , y_train , y_test)

print("part 2")
X_data_2 , Y_data_2 = take_data_2(data_path_2)
random_forest(X_data_2,Y_data_2)




